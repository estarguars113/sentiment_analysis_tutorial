{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
      "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
      "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
      "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
      "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n",
      "         sentiment\n",
      "count  25000.00000\n",
      "mean       0.50000\n",
      "std        0.50001\n",
      "min        0.00000\n",
      "25%        0.00000\n",
      "50%        0.50000\n",
      "75%        1.00000\n",
      "max        1.00000\n",
      "id           object\n",
      "sentiment     int64\n",
      "review       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# load data sources\n",
    "import pandas as pd       \n",
    "train = pd.read_csv(\"data/labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "print(train.head())\n",
    "print(train.describe())\n",
    "print(train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  sentiment                                             review\n",
      "0  \"5814_8\"          1  with all this stuff going down at the moment w...\n",
      "1  \"2381_9\"          1  the classic war of the worlds by timothy hines...\n",
      "2  \"7759_3\"          0  the film starts with a manager nicholas bell g...\n",
      "3  \"3630_4\"          0  it must be assumed that those who praised this...\n",
      "4  \"9495_8\"          1  superbly trashy and wondrously unpretentious s...\n"
     ]
    }
   ],
   "source": [
    "# clean reviews text(remove html markup, number and punctuation signs)\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "pattern = '[^a-zA-Z ]'\n",
    "\n",
    "train['review'] = train.apply(lambda row: re.sub( pattern, '', BeautifulSoup(row['review']).get_text().lower()), axis=1)\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 25000\n",
      "\n",
      "Review 2000 of 25000\n",
      "\n",
      "Review 3000 of 25000\n",
      "\n",
      "Review 4000 of 25000\n",
      "\n",
      "Review 5000 of 25000\n",
      "\n",
      "Review 6000 of 25000\n",
      "\n",
      "Review 7000 of 25000\n",
      "\n",
      "Review 8000 of 25000\n",
      "\n",
      "Review 9000 of 25000\n",
      "\n",
      "Review 10000 of 25000\n",
      "\n",
      "Review 11000 of 25000\n",
      "\n",
      "Review 12000 of 25000\n",
      "\n",
      "Review 13000 of 25000\n",
      "\n",
      "Review 14000 of 25000\n",
      "\n",
      "Review 15000 of 25000\n",
      "\n",
      "Review 16000 of 25000\n",
      "\n",
      "Review 17000 of 25000\n",
      "\n",
      "Review 18000 of 25000\n",
      "\n",
      "Review 19000 of 25000\n",
      "\n",
      "Review 20000 of 25000\n",
      "\n",
      "Review 21000 of 25000\n",
      "\n",
      "Review 22000 of 25000\n",
      "\n",
      "Review 23000 of 25000\n",
      "\n",
      "Review 24000 of 25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split every review into words tokens\n",
    "# remove stop words as connectors and pronouns\n",
    "\n",
    "import nltk\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "english_stop_words = stopwords.words(\"english\")\n",
    "\n",
    "# apply stemmer to remove common words\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def preprocess_reviews(reviews):\n",
    "    processed_reviews = []\n",
    "    num_reviews = len(reviews)\n",
    "    for i in range (0, num_reviews):\n",
    "        r = reviews[i]\n",
    "        tokens = r.split()\n",
    "        tokens = map(\n",
    "            lambda w: ps.stem(w),\n",
    "            list(\n",
    "                filter(\n",
    "                   (lambda w: w not in english_stop_words), \n",
    "                    tokens\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        processed_reviews.append(''.join(tokens))\n",
    "        \n",
    "        if( (i+1)%1000 == 0 ):\n",
    "            print(\"Review %d of %d\\n\" % ( i+1, num_reviews ))\n",
    "        \n",
    "    return processed_reviews\n",
    "\n",
    "processed_reviews = preprocess_reviews(train['review'].tolist())\n",
    "print(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words implementation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
